% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dp.R
\name{computeEnvironmentRx}
\alias{computeEnvironmentRx}
\title{Compute Environment Transitions and Rewards}
\usage{
computeEnvironmentRx(env, model, t, start, end)
}
\arguments{
\item{env}{A list representing the environment, which includes all necessary data structures such as state, action, and scenario spaces.}

\item{model}{An optimization model object used for solving the assignment problem.}

\item{t}{An integer representing the current time step.}

\item{start}{An integer representing the starting index of the state space to be considered.}

\item{end}{An integer representing the ending index of the state space to be considered.}
}
\value{
A matrix where each row represents a transition, containing:
\describe{
\item{next_i}{Index of the next state of the system.}
\item{i}{The current state index.}
\item{j}{The action index.}
\item{kdx}{The scenario index, a combination of Q, D, and W indices.}
}
}
\description{
This function computes the transition matrix and rewards for a given environment over a specified time horizon.
The function iterates over possible states, actions, and scenarios, computing the optimal assignments and
determining the resulting state transitions and associated rewards.
}
\details{
The function works by iterating over the state indices \code{i}, action indices \code{j}, and scenario indices (combinations of \code{Q}, \code{D}, and \code{W}).
For each combination, it computes the optimal assignment using the provided optimization model, and based on the results,
it computes the index of the next state and the reward. If the optimization problem is infeasible, the corresponding transition is skipped.
}
\examples{
\dontrun{
result <- computeEnvironmentRx(env, model, t = 1, start = 1, end = 100)
}

}
